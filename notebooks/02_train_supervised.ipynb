{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e756c7fe-871a-4247-ad59-dc28e7a9a869",
   "metadata": {},
   "source": [
    "## Step 1 Load labeled dataset + basic checks\n",
    "\n",
    "### Goal of this step: \n",
    "- Load the frozen seed dataset\n",
    "- Separate features (X) and target (y)\n",
    "- Verify nothing is broken before modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2f9835-3022-4a63-9c33-48b00ebfd799",
   "metadata": {},
   "source": [
    "### Imports and path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515fd171-4414-46d5-9fc9-2ddf2c8c86be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "import imaplib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b791d913-7793-4ea6-b9f5-06c190d31bf7",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a20fae-08e0-4076-9c1b-4044efefa2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../data/final/final_1000/labeled_1000_samples.csv\")\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "print(\"Shape: \", df.shape)\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b2b206-5c45-4a27-b2d9-72def76869cb",
   "metadata": {},
   "source": [
    "###  Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4b9528-3ec9-4d8a-a3a9-9cce0aff4036",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfc4741-7107-4360-9f78-0ef007852a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e0f927-e351-492c-b190-9a61337e7129",
   "metadata": {},
   "source": [
    "### Check label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b01978-6e0f-4dae-9204-16bc46585e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe01fa6-3332-4e6c-ab07-404656af4fb1",
   "metadata": {},
   "source": [
    "###  Split X and y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dee4f8-98e3-46c5-bffa-eead67440c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\"text_clean\", \"len_words\", \"is_question\"]\n",
    "target_col = \"label\"\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]\n",
    "\n",
    "print(\"X shape : \", X.shape)\n",
    "print(\"y shape : \", y.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5190970d-8828-4e00-a308-f964db2be57d",
   "metadata": {},
   "source": [
    "## Step 2 Train / validation split (STRATIFIED)\n",
    "\n",
    "### Goal of this step:\n",
    "- Split your 1000 labeled samples into:\n",
    "- train set\n",
    "- validation set\n",
    "- Preserve the **class imbalance** this is critical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938ed69b-31a2-45c2-937a-4c81697d4ebf",
   "metadata": {},
   "source": [
    "###  Stratified split \n",
    "\n",
    "We use stratification so the % of important messages stays the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab09179b-bba0-4e23-aa1c-88d6562c099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size = 0.2, \n",
    "    random_state=42, \n",
    "    stratify=y \n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test shape  :\", X_test.shape, y_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3610c6-ca6f-4142-b9d2-fddca7149331",
   "metadata": {},
   "source": [
    "### Verify label distribution stayed correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345f0ca2-5ae3-4354-a39c-1cc282995313",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train label distribution:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nValidation label distribution:\")\n",
    "print(y_test.value_counts(normalize=True)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5538752e-fffd-4679-aeeb-e8e37ab2aef6",
   "metadata": {},
   "source": [
    "## Step 3 Build feature + model pipeline\n",
    "\n",
    "### Define which columns are text and numeric  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac962d43-c245-4287-9bc7-840e5360ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cols = \"text_clean\"\n",
    "num_cols = [\"len_words\", \"is_question\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88cc91f-8a61-47c8-bfae-0999e716277e",
   "metadata": {},
   "source": [
    "### Build preprocessors TF-IDF + numeric passthrough \n",
    "\n",
    "We scale numeric features.\n",
    "TF-IDF already outputs sparse matrix scaler uses with_mean=False to work with sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae9e30d-66d1-4025-971b-0615019db84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 2), \n",
    "    min_df = 2, \n",
    "    max_df = 0.9, \n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler(with_mean=False))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"text\", text_vectorizer, text_cols), \n",
    "        (\"num\", numeric_transformer, num_cols)\n",
    "    ], \n",
    "    remainder=\"drop\"\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b281ae09-a407-4263-824c-ef8e06662eec",
   "metadata": {},
   "source": [
    "### Create the full model pipeline\n",
    "\n",
    "We use class_weight because your dataset is imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9440765d-c346-473a-a666-f880851e6d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(\n",
    "    max_iter=2000, \n",
    "    class_weight=\"balanced\", \n",
    "    n_jobs=None\n",
    ")\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess), \n",
    "    (\"clf\", clf)\n",
    "])\n",
    "\n",
    "model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b310541b-1b80-4c5a-ab19-2aff1dabf4dd",
   "metadata": {},
   "source": [
    "## Step 4 Train + Evaluate \n",
    "\n",
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aec4156-e6b7-407c-b0f9-11e2aa9b859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "print(\"Training done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed7983c-641b-4510-bb71-f293ed5711b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # probability of class 1 \n",
    "\n",
    "print(\"Predictions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354c59d8-d1e1-47c9-bbe8-a27bc518f46f",
   "metadata": {},
   "source": [
    "###   Core metrics precision/recall/F1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004f59a6-bbdd-4fbd-9b55-7d426d9b6315",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, digits=4)) # While Recall asks \"Did we find them all?\", Precision asks \"Of the ones we flagged, how many were actually right?\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2700d75-af36-474b-a56d-cf9f6e9c0445",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"\\nTN (correct skip)      : {tn}\")\n",
    "print(f\"FP (skip predicted imp): {fp}\")\n",
    "print(f\"FN (important missed)  : {fn}\")\n",
    "print(f\"TP (important caught)  : {tp}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b952469-5ff0-474a-8ed9-ddbbe7af8fd9",
   "metadata": {},
   "source": [
    "###  Evaluate different thresholds key for triage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343dbb10-4b88-4f05-a9c1-4869e9989988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_threshold(th):\n",
    "    pred = (y_proba >= th).astype(int)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_test, pred, average=\"binary\", zero_division=0)\n",
    "    return p, r, f1\n",
    "\n",
    "for th in [0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    p, r, f1 = eval_threshold(th)\n",
    "    print(f\"th={th:.1f}  precision={p:.3f}  recall={r:.3f}  f1={f1:.3f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea99fc1-1ad6-4936-ad6e-37b467270f32",
   "metadata": {},
   "source": [
    "### Save model with joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed9a60e-b6fb-4999-906d-35f5a46571ee",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "**Model & Pipeline**\n",
    "- TF-IDF vectorization on text (`ngram_range=(1,2)`)\n",
    "- Numeric feature scaling\n",
    "- Logistic Regression with `class_weight=\"balanced\"`\n",
    "- Implemented using `ColumnTransformer` + `Pipeline` for clean separation of preprocessing and modeling\n",
    "\n",
    "**Evaluation (Validation Set)**\n",
    "- Accuracy: ~0.76 (not primary metric)\n",
    "- For **important class (1)** at default threshold 0.5:\n",
    "  - Precision ≈ 0.26\n",
    "  - Recall ≈ 0.41\n",
    "- Confusion matrix:\n",
    "  - TP: 11 | FN: 16 | FP: 32 | TN: 139\n",
    "\n",
    "**Threshold Analysis (Key Insight)**\n",
    "- For a triage system, recall is prioritized over precision\n",
    "- At threshold **0.3**:\n",
    "  - Recall ≈ **0.59**\n",
    "  - Precision ≈ 0.24\n",
    "- This significantly reduces missed important messages at the cost of acceptable notification noise\n",
    "\n",
    "**Conclusion**\n",
    "- The baseline model captures meaningful patterns despite limited labeled data\n",
    "- Performance is sufficient to bootstrap **semi-supervised learning**\n",
    "- This model is used as a seed to auto-label high-confidence samples in the next notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f324576-2819-47c8-88d8-a54acaae095d",
   "metadata": {},
   "source": [
    "## Save model with joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afda6cc1-7853-43cb-ae78-1b4dbd16bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "MODEL_DIR = Path(\"../models\")\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_PATH = MODEL_DIR / \"tg_logreg.joblib\"\n",
    "\n",
    "joblib.dump(model, MODEL_PATH)\n",
    "\n",
    "print(\"Model saved to:\", MODEL_PATH.resolve()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341e6e41-2c74-4c53-9b24-5a874e013cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
