{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5a2b68c",
   "metadata": {},
   "source": [
    "# TG Bot — Preprocessing (Personal Chats Only)\n",
    "`Goal:` turn Telegram JSON export into a clean dataset for manual labeling and model training\n",
    "\n",
    "**Outputs**:\n",
    "- `clean_messages.csv` — clean messages from personal chats only\n",
    "- `to_label_personal_balanced_1000.csv` — balanced sample for manual labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce70dbf0",
   "metadata": {},
   "source": [
    "## 1) Load JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9784b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "JSON_PATH = Path(\"../data/personal_chats.json\")\n",
    "\n",
    "assert JSON_PATH.exists(), f\"File not found: {JSON_PATH.resolve()}\"\n",
    "print(\"Using:\", JSON_PATH.resolve())\n",
    "\n",
    "with JSON_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(\"Top-level type:\", type(data))\n",
    "if isinstance(data, dict):\n",
    "    print(\"Top-level keys (first 30):\", list(data.keys())[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2160ce",
   "metadata": {},
   "source": [
    "## 2) Helpers: extract chats + normalize Telegram `text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a65c8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tg_text_to_str(text_field):\n",
    "    if text_field is None:\n",
    "        return \"\"\n",
    "    if isinstance(text_field, str):\n",
    "        return text_field\n",
    "    if isinstance(text_field, list):\n",
    "        out = []\n",
    "        for part in text_field:\n",
    "            if isinstance(part, str):\n",
    "                out.append(part)\n",
    "            elif isinstance(part, dict):\n",
    "                out.append(part.get(\"text\", \"\"))\n",
    "        return \"\".join(out)\n",
    "    return str(text_field)\n",
    "\n",
    "\n",
    "def extract_message_blocks(data):\n",
    "    blocks = []\n",
    "\n",
    "    if isinstance(data, dict) and isinstance(data.get(\"messages\"), list):\n",
    "        blocks.append({\n",
    "            \"chat_name\": data.get(\"name\", data.get(\"title\", \"unknown_chat\")),\n",
    "            \"chat_type\": data.get(\"type\", None),\n",
    "            \"messages\": data[\"messages\"],\n",
    "        })\n",
    "        return blocks\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        chats = data.get(\"chats\")\n",
    "        if isinstance(chats, dict):\n",
    "            chat_list = chats.get(\"list\")\n",
    "            if isinstance(chat_list, list):\n",
    "                for chat in chat_list:\n",
    "                    if isinstance(chat, dict) and isinstance(chat.get(\"messages\"), list):\n",
    "                        blocks.append({\n",
    "                            \"chat_name\": chat.get(\"name\", chat.get(\"title\", \"unknown_chat\")),\n",
    "                            \"chat_type\": chat.get(\"type\", None),\n",
    "                            \"messages\": chat[\"messages\"],\n",
    "                        })\n",
    "                if blocks:\n",
    "                    return blocks\n",
    "\n",
    "    return blocks\n",
    "\n",
    "\n",
    "blocks = extract_message_blocks(data)\n",
    "print(\"Chats found:\", len(blocks))\n",
    "print(\"Example chat:\", blocks[0][\"chat_name\"] if blocks else \"NONE\")\n",
    "print(\"Example type:\", blocks[0].get(\"chat_type\") if blocks else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a561983d",
   "metadata": {},
   "source": [
    "## 3) Flatten to DataFrame (minimal fields)\n",
    "We keep only the fields we need for cleaning + labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e01e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for block in blocks:\n",
    "    chat_name = block[\"chat_name\"]\n",
    "    chat_type = block.get(\"chat_type\")\n",
    "\n",
    "    for m in block[\"messages\"]:\n",
    "        if not isinstance(m, dict):\n",
    "            continue\n",
    "\n",
    "        rows.append({\n",
    "            \"chat_name\": chat_name,\n",
    "            \"chat_type\": chat_type,\n",
    "            \"msg_id\": m.get(\"id\"),\n",
    "            \"date\": m.get(\"date\"),\n",
    "            \"from_name\": m.get(\"from\"),\n",
    "            \"from_id\": m.get(\"from_id\"),\n",
    "            \"type\": m.get(\"type\"),\n",
    "            \"text_raw\": tg_text_to_str(m.get(\"text\")),\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6b4f8b",
   "metadata": {},
   "source": [
    "## 4) Filter to personal chats only\n",
    "\n",
    "Telegram exports differ, so we use a **robust heuristic**:\n",
    "1) If `chat_type` exists and looks like a private/personal chat → keep\n",
    "2) Otherwise, infer personal chats by **number of unique senders per chat** ≤ 2 usually means you + one person\n",
    "3) Exclude obvious groups/channels by name patterns\n",
    "\n",
    "This is conservative: it may drop a few true DMs, but it avoids group noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79af76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "\n",
    "# Basic clean\n",
    "df2[\"chat_name\"] = df2[\"chat_name\"].fillna(\"\").astype(str)\n",
    "df2[\"from_id\"] = df2[\"from_id\"].fillna(\"\").astype(str)\n",
    "df2[\"from_name\"] = df2[\"from_name\"].fillna(\"\").astype(str)\n",
    "df2[\"type\"] = df2[\"type\"].fillna(\"\").astype(str)\n",
    "df2[\"text_raw\"] = df2[\"text_raw\"].fillna(\"\").astype(str)\n",
    "\n",
    "# Remove service + empty early so sender-count heuristic works on real messages\n",
    "df2[\"is_service\"] = df2[\"type\"].str.lower().eq(\"service\")\n",
    "df2[\"is_empty_text\"] = df2[\"text_raw\"].str.strip().eq(\"\")\n",
    "df2 = df2[~df2[\"is_service\"] & ~df2[\"is_empty_text\"]].copy()\n",
    "\n",
    "# Exclude obvious groups/channels by name patterns edit if needed\n",
    "GROUP_NAME_RE = re.compile(r\"(\\||\\bgroup\\b|\\bchannel\\b|\\bканал\\b|\\bчат\\b|\\bобъявлен|announcement|broadcast)\", re.I)\n",
    "df2[\"name_looks_group\"] = df2[\"chat_name\"].str.contains(GROUP_NAME_RE)\n",
    "\n",
    "# If chat_type exists, use it as a hint\n",
    "# Common values seen in exports 'personal_chat', 'private', 'public_group', 'private_group', 'channel'\n",
    "df2[\"chat_type_norm\"] = df2[\"chat_type\"].fillna(\"\").astype(str).str.lower()\n",
    "df2[\"type_looks_personal\"] = df2[\"chat_type_norm\"].str.contains(r\"(personal|private)\", regex=True) & ~df2[\"chat_type_norm\"].str.contains(r\"(group|channel)\", regex=True)\n",
    "\n",
    "# Sender-count heuristic personal chat usually has <= 2 distinct from_id\n",
    "sender_counts = df2.groupby(\"chat_name\")[\"from_id\"].nunique().rename(\"n_unique_senders\")\n",
    "df2 = df2.merge(sender_counts, on=\"chat_name\", how=\"left\")\n",
    "df2[\"looks_personal_by_senders\"] = df2[\"n_unique_senders\"].fillna(999).astype(int) <= 2\n",
    "\n",
    "# Final keep rule:\n",
    "# - keep if chat_type says personal OR sender heuristic says personal\n",
    "# - AND chat_name does NOT look like group\n",
    "df_personal = df2[(df2[\"type_looks_personal\"] | df2[\"looks_personal_by_senders\"]) & (~df2[\"name_looks_group\"])].copy()\n",
    "\n",
    "print(\"After personal-chat filter:\", len(df_personal))\n",
    "print(\"Unique chats kept:\", df_personal[\"chat_name\"].nunique())\n",
    "\n",
    "df_personal[\"chat_name\"].value_counts().head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a4b0f3",
   "metadata": {},
   "source": [
    "## 5) Clean text (light cleaning) + minimal features\n",
    "We keep cleaning **simple** so you don't destroy meaning.\n",
    "Tokens like `<URL>` and `<USER>` help the model learn patterns without memorizing specifics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3722a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_RE = re.compile(r\"\"\"(?i)\\b((?:https?://|www\\.)\\S+)\\b\"\"\")\n",
    "MENTION_RE = re.compile(r\"(?<!\\w)@\\w+\")\n",
    "MULTISPACE_RE = re.compile(r\"\\s+\")\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    s = str(s).replace(\"\\n\", \" \").replace(\"\\t\", \" \").lower()\n",
    "    s = URL_RE.sub(\" <URL> \", s)\n",
    "    s = MENTION_RE.sub(\" <USER> \", s)\n",
    "    s = MULTISPACE_RE.sub(\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "df_personal[\"text_clean\"] = df_personal[\"text_raw\"].apply(clean_text)\n",
    "\n",
    "# Minimal features good for baseline + later rules \n",
    "df_personal[\"len_words\"] = df_personal[\"text_clean\"].str.split().apply(len)\n",
    "df_personal[\"has_url\"] = df_personal[\"text_clean\"].str.contains(r\"<URL>\", regex=True)\n",
    "df_personal[\"is_question\"] = df_personal[\"text_raw\"].str.contains(r\"\\?\", na=False) | df_personal[\"text_clean\"].str.startswith((\"why \", \"how \", \"what \", \"when \", \"where \"))\n",
    "\n",
    "# Remove ultra short noise tweak threshold if you want \n",
    "df_personal = df_personal[(df_personal[\"len_words\"] >= 2) | (df_personal[\"is_question\"])].copy()\n",
    "\n",
    "# Deduplicate within same chat+sender+text\n",
    "before = len(df_personal)\n",
    "df_personal = df_personal.drop_duplicates(subset=[\"chat_name\", \"from_id\", \"text_clean\"])\n",
    "print(\"Dedup removed:\", before - len(df_personal))\n",
    "print(\"Rows now:\", len(df_personal))\n",
    "\n",
    "df_personal[[\"chat_name\",\"from_name\",\"text_clean\",\"len_words\",\"is_question\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12df738",
   "metadata": {},
   "source": [
    "## 6) Export clean personal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cbc144",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = Path(\"../data/final\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "keep_cols = [\n",
    "    \"chat_name\",\"msg_id\",\"date\",\"from_name\",\"from_id\",\n",
    "    \"text_raw\",\"text_clean\",\n",
    "    \"len_words\",\"has_url\",\"is_question\"\n",
    "]\n",
    "\n",
    "df_clean = df_personal[keep_cols].copy()\n",
    "\n",
    "clean_path = OUT_DIR / \"personal_clean_messages.csv\"\n",
    "df_clean.to_csv(clean_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Saved:\", clean_path.resolve())\n",
    "print(\"Rows :\", len(df_clean))\n",
    "df_clean.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abb3f67",
   "metadata": {},
   "source": [
    "## 7) Balanced sampling for manual labeling by sender\n",
    "Goal: your labeling file should not be dominated by 1–2 people.\n",
    "\n",
    "Strategy:\n",
    "- Pick top senders (in personal chats) by message count.\n",
    "- Sample **up to `MAX_PER_SENDER`** messages per sender.\n",
    "- Ensure enough diversity.\n",
    "\n",
    "Output: `to_label_personal_balanced_1000.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae098c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_senders = df_clean[\"from_name\"].value_counts().head(30)\n",
    "top_senders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86420b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TOTAL = 1000\n",
    "MAX_PER_SENDER = 80      # cap so one person does not dominate\n",
    "MIN_PER_SENDER = 15      # try to get at least this many from a sender if they have enough\n",
    "\n",
    "df_lab = df_clean.copy()\n",
    "df_lab[\"from_name\"] = df_lab[\"from_name\"].fillna(\"\").astype(str)\n",
    "\n",
    "# Order senders by frequency\n",
    "sender_order = df_lab[\"from_name\"].value_counts().index.tolist()\n",
    "\n",
    "samples = []\n",
    "remaining = N_TOTAL\n",
    "\n",
    "rng = 42\n",
    "\n",
    "for sender in sender_order:\n",
    "    if remaining <= 0:\n",
    "        break\n",
    "    pool = df_lab[df_lab[\"from_name\"] == sender]\n",
    "    if len(pool) == 0:\n",
    "        continue\n",
    "\n",
    "    # How many to take from this sender\n",
    "    take = min(MAX_PER_SENDER, len(pool))\n",
    "    # If we still have lots remaining, try to take at least MIN_PER_SENDER\n",
    "    if remaining > 0:\n",
    "        take = min(take, remaining)\n",
    "        if take < MIN_PER_SENDER and len(pool) >= MIN_PER_SENDER and remaining >= MIN_PER_SENDER:\n",
    "            take = MIN_PER_SENDER\n",
    "\n",
    "    samples.append(pool.sample(take, random_state=rng))\n",
    "    remaining -= take\n",
    "\n",
    "to_label = pd.concat(samples, ignore_index=True)\n",
    "\n",
    "# If still not enough rare, top up with random from whole pool\n",
    "if len(to_label) < N_TOTAL:\n",
    "    need = N_TOTAL - len(to_label)\n",
    "    extra = df_lab.drop(to_label.index, errors=\"ignore\")\n",
    "    if len(extra) > 0:\n",
    "        to_label = pd.concat([to_label, extra.sample(min(need, len(extra)), random_state=99)], ignore_index=True)\n",
    "\n",
    "# Final shuffle + label column\n",
    "to_label = to_label.drop_duplicates(subset=[\"chat_name\",\"from_id\",\"text_clean\"])\n",
    "to_label = to_label.sample(min(N_TOTAL, len(to_label)), random_state=123).copy()\n",
    "to_label[\"label\"] = \"\" \n",
    "\n",
    "out_path = OUT_DIR / \"to_label_personal_balanced_1000.csv\"\n",
    "to_label.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Saved:\", out_path.resolve())\n",
    "print(\"Rows :\", len(to_label))\n",
    "print(\"\\nPer-sender counts (top 15):\")\n",
    "print(to_label[\"from_name\"].value_counts().head(15))\n",
    "\n",
    "to_label.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a602bc24",
   "metadata": {},
   "source": [
    "### 8) Some preprocessing steps for dataset labeled_1000_samples_manually.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36af631-61c9-4d76-aef8-e7f6300f2b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "PATH = \"../data/final/labeled_1000_samples_manually.csv\"  \n",
    "\n",
    "df = pd.read_csv(PATH)\n",
    "\n",
    "if \"label\" not in df.columns:\n",
    "    df[\"label\"] = \"\"\n",
    "\n",
    "def normalize_label(x):\n",
    "    if pd.isna(x):\n",
    "        return \"-\"\n",
    "    s = str(x).strip()\n",
    "\n",
    "    if s == \"\":\n",
    "        return \"-\"\n",
    "\n",
    "    # keep only + and - characters\n",
    "    s = \"\".join(ch for ch in s if ch in \"+-\")\n",
    "\n",
    "    if s == \"\":\n",
    "        return \"-\"\n",
    "\n",
    "    return \"+\" if \"+\" in s else \"-\"\n",
    "\n",
    "df[\"label\"] = df[\"label\"].apply(normalize_label)\n",
    "\n",
    "print(df[\"label\"].value_counts(dropna=False)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095448e3-6e5f-43dc-a7f4-1462c271d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec42c432-3ee2-47b4-9d62-dc598b8bac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = df.copy() \n",
    "\n",
    "# label: + / - => 1 / 0 \n",
    "df_ml[\"label\"] = df_ml[\"label\"].map({\"+\": 1, \"-\": 0})\n",
    "\n",
    "# booleans => int\n",
    "df_ml[\"is_question\"] = df_ml[\"is_question\"].astype(int)\n",
    "\n",
    "# select only what the model needs\n",
    "FEATURE_COLS = [\"text_clean\", \"len_words\", \"is_question\", \"label\"]\n",
    "df_ml = df_ml[FEATURE_COLS]\n",
    "\n",
    "df_ml.info()\n",
    "df_ml.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cbbc39-912a-4587-a679-cf67e5f764cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "OUT_DIR = Path(\"../data/final\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "out_path = OUT_DIR / \"labeled_1000_samples.csv\"\n",
    "\n",
    "df_ml.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Saved:\", out_path.resolve())\n",
    "df_ml.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5d73c8-388a-4588-a981-7585dfc0af27",
   "metadata": {},
   "source": [
    "### 9) Save final labeled_1000_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee13936b-4340-4f4d-b971-813be9933a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb17fd0c-34ad-40a7-9343-504b98adca45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
