{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "648706cb-f170-438e-a32a-a0de5bebbabf",
   "metadata": {},
   "source": [
    "##  Step 1 Load datasets + create _label\n",
    "\n",
    "### imports and path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd5e20f-3d26-47a8-9921-687b17280b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67590e29-6cc0-4f9d-a005-8447b1477a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_path = Path(\"../data/final/final_1000/labeled_1000_samples.csv\")\n",
    "unlabeled_path = Path(\"../data/final/final_full/ready_messages.csv\")\n",
    "\n",
    "assert labeled_path.exists(), f\"Missing: {labeled_path.resolve()}\"\n",
    "assert unlabeled_path.exists(), f\"Missing: {unlabeled_path.resolve()}\"\n",
    "\n",
    "print(\"Labeled  :\", labeled_path.resolve())\n",
    "print(\"Unlabeled:\", unlabeled_path.resolve())  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba80ba0a-b033-4205-b12d-cf5ca8177c43",
   "metadata": {},
   "source": [
    " ### Load both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773814f7-f352-453c-aa48-ad209a7a5555",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lab = pd.read_csv(labeled_path)\n",
    "df_unlab = pd.read_csv(labeled_path)\n",
    "\n",
    "print(\"df_lab shape  :\", df_lab.shape)\n",
    "print(\"df_unlab shape:\", df_unlab.shape)\n",
    "\n",
    "df_lab.head(5), df_unlab.head(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0a1d22-67f9-4d8d-92a4-580558da801f",
   "metadata": {},
   "source": [
    "### Create _label anchors and combine\n",
    "\n",
    "- _label = label for labeled\n",
    "- _label = -1 for unlabeled (unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb335a4-5aef-4a5e-888c-5be8e6892296",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\"text_clean\", \"len_words\", \"is_question\"]\n",
    "\n",
    "\n",
    "df_lab2 = df_lab[feature_cols + [\"label\"]].copy()\n",
    "df_lab2[\"_label\"] = df_lab2[\"label\"].astype(int)\n",
    "df_lab2[\"_is_labeled\"] = 1\n",
    "\n",
    "df_unlab2 = df_unlab[feature_cols].copy()\n",
    "df_unlab2[\"_label\"] = -1\n",
    "df_unlab2[\"_is_labeled\"] = 0\n",
    "\n",
    "df_all = pd.concat([df_lab2, df_unlab2], ignore_index=True)\n",
    "\n",
    "df_all[\"len_words\"] = df_all[\"len_words\"].astype(int)\n",
    "df_all[\"is_question\"] = df_all[\"is_question\"].astype(int)\n",
    "df_all[\"_label\"] = df_all[\"_label\"].astype(int)\n",
    "\n",
    "print(\"df_all shape:\", df_all.shape)\n",
    "df_all.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d314fc-61fd-408e-bb37-ed8861c60286",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "\n",
    "Vectorize text for clustering (TF-IDF)\n",
    "\n",
    "**Goal**:\n",
    "- Build a shared TF-IDF space for all messages (labeled + unlabeled)\n",
    "- This space will be used only for clustering\n",
    "- We reuse the same philosophy as Notebook 2, but this vectorizer is independent "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af02946f-82b7-4e08-9c24-e1475ee76232",
   "metadata": {},
   "source": [
    "## Create TF-IDF vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1a2344-c18f-446f-8a8c-556847d8f8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_cluster = TfidfVectorizer(\n",
    "    ngram_range=(1, 2), \n",
    "    min_df=2, \n",
    "    max_df=0.9, \n",
    "    sublinear_tf=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c667bafc-224b-4249-92c7-bf77325da2bd",
   "metadata": {},
   "source": [
    "Why:\n",
    "- unigrams + bigrams → captures “can you”, “are you”\n",
    "- min_df=2 → removes typos / ultra-rare noise\n",
    "- max_df=0.9 → removes useless global words\n",
    "\n",
    "\n",
    "## Fit TF-IDF on all messages \n",
    "\n",
    "This is important:\n",
    "- fit on df_all, not only labeled\n",
    "- Clustering must see the whole distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbac747b-5414-4fec-b111-90da2e18f526",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text = tfidf_cluster.fit_transform(df_all[\"text_clean\"])\n",
    "print(\"TF-IDF matrix shape :\", X_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd92a010-421a-486a-8277-07f484adad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sparse matrix type:\", type(X_text))\n",
    "print(\"Density:\", X_text.nnz / (X_text.shape[0] * X_text.shape[1])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc758619-3d7b-4893-a54a-3a5033373332",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "\n",
    "Cluster messages with **MiniBatchKMeans**\n",
    "\n",
    "Why MiniBatchKMeans?\n",
    "- works with large sparse TF-IDF matrices\n",
    "- faster than full KMeans\n",
    "- good enough for our purpose group similar messages\n",
    "\n",
    "### Choose number of clusters and fit\n",
    "\n",
    "Start with k=300 good default. You can adjust later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54694540-5b85-4dc1-b2b4-e340e8322ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 300\n",
    "\n",
    "kmeans = MiniBatchKMeans(\n",
    "    n_clusters=k,\n",
    "    random_state=42,\n",
    "    batch_size=2048,\n",
    "    n_init=\"auto\"\n",
    ")\n",
    "\n",
    "clusters = kmeans.fit_predict(X_text)\n",
    "\n",
    "df_all[\"cluster\"] = clusters\n",
    "\n",
    "print(\" Clustering done\")\n",
    "print(\"Clusters shape:\", clusters.shape)\n",
    "print(\"Unique clusters:\", df_all[\"cluster\"].nunique())\n",
    "df_all[[\"cluster\", \"_is_labeled\", \"_label\", \"text_clean\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3649c592-b4da-4fb1-885c-6a968a6843ce",
   "metadata": {},
   "source": [
    "## Check how many labeled anchors per cluster \n",
    "\n",
    "This tells us whether clusters are can propagate or empty "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f8f2e2-97a0-432d-852f-2a9ed2304bed",
   "metadata": {},
   "source": [
    "## Check how many labeled anchors per cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3713c24-fea8-414c-b9e2-f267fe5d8dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors_per_cluster = (\n",
    "    df_all[df_all[\"_is_labeled\"] == 1]\n",
    "    .groupby(\"cluster\")\n",
    "    .size()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "print(\"Anchored clusters:\", anchors_per_cluster.shape[0], \"out of\", k)\n",
    "print(\"\\nTop 15 clusters by #anchors:\")\n",
    "display(anchors_per_cluster.head(15)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8695d60-5b6c-430e-9b3c-83f513d5379b",
   "metadata": {},
   "source": [
    "### Inspect a few clusters (sanity check) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d95421-76e8-489a-8408-df650de90467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cluster(c, n=10):\n",
    "    sample = df_all[df_all[\"cluster\"] == c].sample(min(n, (df_all[\"cluster\"] == c).sum()), random_state=42)\n",
    "    return sample[[\"_is_labeled\", \"_label\", \"text_clean\"]]\n",
    "\n",
    "some_clusters = anchors_per_cluster.head(10).index.tolist() if len(anchors_per_cluster) >= 3 else df_all[\"cluster\"].dropna().unique()[:3]\n",
    "\n",
    "for c in some_clusters:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Cluster {c} | size={(df_all['cluster']==c).sum()} | anchors={anchors_per_cluster.get(c, 0)}\")\n",
    "    display(show_cluster(c, n=12)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0006cf-b16d-4b40-a006-a47e2ba26690",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "\n",
    "Propagate labels using existing anchors majority vote\n",
    "\n",
    "### majority vote propagation \n",
    "\n",
    "Rules:\n",
    "- Only propagate in clusters that have anchors\n",
    "- Use majority label of anchors\n",
    "- Do NOT overwrite human labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b4214-bee4-4e4d-b2ca-388ba2ddb4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_all[\"prop_label\"] = np.nan\n",
    "\n",
    "for c in range(k):\n",
    "    idx = df_all.index[df_all[\"cluster\"] == c]\n",
    "    \n",
    "    anchors = df_all.loc[idx][df_all.loc[idx][\"_is_labeled\"] == 1]\n",
    "    \n",
    "    if len(anchors) == 0:\n",
    "        continue \n",
    "    \n",
    "    # majority label among anchors \n",
    "    majority_label = anchors[\"_label\"].mode()[0]\n",
    "    \n",
    "    # assign to ALL points in cluster\n",
    "    df_all.loc[idx, \"prop_label\"] = majority_label "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccccae0-bf82-4b27-8111-c3374e69ced4",
   "metadata": {},
   "source": [
    "### Check propagation coverage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3054c27f-a446-442f-a608-6df6e211c17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total messages:\", len(df_all))\n",
    "print(\"Propagated labels:\", df_all[\"prop_label\"].notna().sum())\n",
    "print(\"Still unlabeled:\", df_all[\"prop_label\"].isna().sum())\n",
    "\n",
    "df_all[\"prop_label\"].value_counts(dropna=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef75890-a225-4cef-a18a-45151a74e944",
   "metadata": {},
   "source": [
    "## Step 5 \n",
    "\n",
    "Distance filtering keep closest X% per cluster\n",
    "\n",
    "What this does\n",
    "\n",
    "For each cluster:\n",
    "- compute distance of every point to its centroid\n",
    "- keep only the closest 50% \n",
    "- discard the far points (likely boundary / mixed) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476b394d-2356-4fd9-9b6d-60241e82c71a",
   "metadata": {},
   "source": [
    "###  Compute distances to cluster centroids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e5b812-45f6-4d8d-8e72-c7ff5fae5c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = kmeans.transform(X_text)\n",
    "\n",
    "# distance of each point to its assigned centroid\n",
    "dist_to_centroid = D[np.arange(len(df_all)), df_all[\"cluster\"].values]\n",
    "\n",
    "df_all[\"dist_to_centroid\"] = dist_to_centroid\n",
    "df_all[\"dist_to_centroid\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d9024c-2630-4d66-a365-78048e59a70f",
   "metadata": {},
   "source": [
    "###  Keep closest percentile per cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e45c7c6-aacc-4669-92cb-21d1c85aee96",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_closest = 50  # keep closest 50% of each cluster\n",
    "\n",
    "keep_mask = np.zeros(len(df_all), dtype=bool)\n",
    "\n",
    "for c in range(k):\n",
    "    idx = np.where(df_all[\"cluster\"].values == c)[0]\n",
    "    if len(idx) == 0:\n",
    "        continue\n",
    "    \n",
    "    d = df_all[\"dist_to_centroid\"].values[idx]\n",
    "    cutoff = np.percentile(d, percentile_closest)\n",
    "    keep_mask[idx] = d <= cutoff\n",
    "\n",
    "df_keep = df_all[keep_mask].copy()\n",
    "print(\"Kept after distance filter:\", len(df_keep), \"out of\", len(df_all)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409c9ee8-c1fd-4fea-9ccf-e5f3376319ac",
   "metadata": {},
   "source": [
    "### Keep only rows that actually got propagated labels\n",
    "\n",
    "We only want points in anchored clusters they have prop_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a231d3d-b0b4-43ad-953f-a72ca3b70019",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keep = df_keep[df_keep[\"prop_label\"].notna()].copy()\n",
    "print(\"Kept + propagated:\", len(df_keep))\n",
    "df_keep[\"prop_label\"].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd176634-2a0e-4b7f-8b7f-eaa880d04623",
   "metadata": {},
   "source": [
    "Build pseudo-labeled dataset from unlabeled only\n",
    "\n",
    "We will create a file for training:\n",
    "- take only unlabeled rows (_is_labeled == 0)\n",
    "- use prop_label as label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fa864f-3310-46a9-9777-e4640bc4d1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo = df_keep[df_keep[\"_is_labeled\"] == 0].copy()\n",
    "pseudo[\"label\"] = pseudo[\"prop_label\"].astype(int)\n",
    "\n",
    "print(\"Pseudo-labeled rows (from unlabeled):\", len(pseudo))\n",
    "pseudo[[\"label\", \"text_clean\", \"len_words\", \"is_question\"]].head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de71a80-6bce-4a8e-a105-b5ec4b3b6451",
   "metadata": {},
   "source": [
    "### Save pseudo-labeled dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6d508e-a72f-45d4-a01d-774287ec631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = Path(\"../data/final\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pseudo_path = OUT_DIR / \"pseudo_labeled_cluster_filtered.csv\"\n",
    "pseudo.to_csv(pseudo_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Saved:\", pseudo_path.resolve()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca239e73-8806-48e6-a81c-33523adbbcfd",
   "metadata": {},
   "source": [
    "What we have now important\n",
    "\n",
    "You now produced high confidence pseudo labels using:\n",
    "- clustering\n",
    "- majority label propagation from your 1000 anchors\n",
    "- distance filtering to reduce noise\n",
    "\n",
    "This is exactly Géron’s method, adapted to your text "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb79b65c-d7a1-4728-99ac-d7989a3193db",
   "metadata": {},
   "source": [
    "## Step 6 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ede8e87-02a0-4c00-821f-7a0f6bd805af",
   "metadata": {},
   "source": [
    "#### Merge datasets = > retrain supervised model = >  evaluate\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30376686-5af0-4eab-99ef-9ce1c7af5f71",
   "metadata": {},
   "source": [
    "### Load seed + pseudo datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb43b02-376f-4ec7-ad3d-621799774257",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_path = Path(\"../data/final/final_1000/labeled_1000_samples.csv\")\n",
    "pseudo_path = Path(\"../data/final/pseudo_labeled_cluster_filtered.csv\")\n",
    "\n",
    "df_seed = pd.read_csv(seed_path)\n",
    "df_pseudo = pd.read_csv(pseudo_path)\n",
    "\n",
    "print(\"Seed  :\", df_seed.shape)\n",
    "print(\"Pseudo :\", df_pseudo.shape)\n",
    "\n",
    "df_seed.head(2), df_pseudo.head(2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c9082d-73f7-428e-acbe-4858ce6a81b2",
   "metadata": {},
   "source": [
    "### Keep only model columns + clean dtypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac957087-8ceb-44a1-b1aa-9dd09887e575",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\"text_clean\", \"len_words\", \"is_question\"]\n",
    "target_col = \"label\"\n",
    "\n",
    "df_seed = df_seed[feature_cols + [target_col]].copy()\n",
    "df_pseudo = df_pseudo[feature_cols + [target_col]].copy()\n",
    "\n",
    "# enforce types\n",
    "for col in [\"len_words\", \"is_question\", \"label\"]:\n",
    "    df_seed[col] = df_seed[col].astype(int)\n",
    "    df_pseudo[col] = df_pseudo[col].astype(int)\n",
    "\n",
    "print(\"Seed label distribution:\\n\", df_seed[\"label\"].value_counts())\n",
    "print(\"\\nPseudo label distribution:\\n\", df_pseudo[\"label\"].value_counts()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd782784-11ec-46c4-8188-96d36b476dc8",
   "metadata": {},
   "source": [
    "### Merge to create semi-supervised training dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d111ff74-9889-4943-9fea-f45ae8877109",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_semi = pd.concat([df_seed, df_pseudo], ignore_index=True)\n",
    "\n",
    "print(\"Semi dataset shape:\", df_semi.shape)\n",
    "print(\"\\nSemi label distribution:\\n\", df_semi[\"label\"].value_counts(normalize=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fabd59-645e-4d1d-86ad-c64861a5f3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = Path(\"../data/final/train_semi_supervised.csv\")\n",
    "df_semi.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
    "print(\"Saved:\", out_path.resolve()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef39c583-f134-4a98-876b-b2e8b12c1e19",
   "metadata": {},
   "source": [
    "### Train/Test split stratified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef198e1-a1be-47ce-9446-fce2ec620151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_semi[feature_cols]\n",
    "y = df_semi[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Test  :\", X_test.shape, y_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01608139-786e-4d4a-b213-0d7041e417d2",
   "metadata": {},
   "source": [
    "### Build the SAME model pipeline as Notebook 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09768381-8cf5-42b0-a39e-166065cffd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_col = \"text_clean\"\n",
    "num_col = [\"len_words\", \"is_question\"]\n",
    "\n",
    "text_vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.9,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler(with_mean=False))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"text\", text_vectorizer, text_col),\n",
    "        (\"num\", numeric_transformer, num_col),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_semi = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"clf\", clf),\n",
    "]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7664718-4080-4c50-ad57-568c266c541b",
   "metadata": {},
   "source": [
    "### Train + evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb0b9fd-a808-492f-9cc7-19a10862675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "model_semi.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_semi.predict(X_val)\n",
    "y_proba = model_semi.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(\"Semi-supervised model trained\\n\")\n",
    "print(classification_report(y_val, y_pred, digits=4))\n",
    "\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"\\nTN: {tn}  FP: {fp}  FN: {fn}  TP: {tp}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a93dc1-098d-45ad-a4be-b019886f9bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_threshold(th):\n",
    "    pred = (y_proba >= th).astype(int)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(\n",
    "        y_val, pred, average=\"binary\", zero_division=0\n",
    "    )\n",
    "    return p, r, f1\n",
    "\n",
    "for th in [0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    p, r, f1 = eval_threshold(th)\n",
    "    print(f\"th={th:.1f}  precision={p:.3f}  recall={r:.3f}  f1={f1:.3f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7774b0f7-8b9c-42b8-8cfe-c7b9126d6b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.3\n",
    "\n",
    "y_pred_final = (y_proba >= THRESHOLD).astype(int)\n",
    "\n",
    "print(\"Using threshold =\", THRESHOLD)\n",
    "print(classification_report(y_val, y_pred_final, digits=4))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_val, y_pred_final))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8308d0e3-587c-4014-8c16-a72a27637e4f",
   "metadata": {},
   "source": [
    "### Save the model joblib  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d596be-89ca-40c6-9854-7496f954574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib \n",
    "\n",
    "MODEL_DIR = Path(\"../models\")\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_PATH = MODEL_DIR / \"tg_logreg_semi_cluster.joblib\"\n",
    "\n",
    "joblib.dump(model_semi, MODEL_PATH)\n",
    "\n",
    "print(\" Model saved to:\", MODEL_PATH.resolve()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e1ab99-5e96-48cc-a86e-54c285c4ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "CONFIG_PATH = MODEL_DIR / \"tg_config.json\"\n",
    "\n",
    "config = {\n",
    "    \"threshold\": 0.3,\n",
    "    \"positive_class\": \"important\",\n",
    "    \"negative_class\": \"skip\",\n",
    "    \"notes\": \"Chosen to prioritize recall (~70%+) for important messages\"\n",
    "}\n",
    "\n",
    "with open(CONFIG_PATH, \"w\") as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(\" Config saved to:\", CONFIG_PATH.resolve())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3bfc0b-7fa9-4f17-9071-1caf5ed2f12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = joblib.load(MODEL_PATH)\n",
    "\n",
    "# sanity check\n",
    "proba_test = loaded_model.predict_proba(X_val)[:, 1]\n",
    "pred_test = (proba_test >= 0.3).astype(int)\n",
    "\n",
    "print(\"Load test OK. Predictions:\", pred_test[:10]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766dc0ca-8c17-4259-bb09-00ca180098b1",
   "metadata": {},
   "source": [
    "### Goal \n",
    "Improve recall for **important Telegram messages** without additional manual labeling by leveraging a large pool of unlabeled data.\n",
    "\n",
    "---\n",
    "\n",
    "### Method\n",
    "This notebook implements a **semi-supervised learning pipeline inspired by label propagation**:\n",
    "\n",
    "1. **Anchor labels**  \n",
    "   Started from ~1,000 manually labeled messages (`important` / `skip`).\n",
    "\n",
    "2. **Shared representation**  \n",
    "   All labeled and unlabeled messages were embedded into a common **TF-IDF space** (unigrams + bigrams).\n",
    "\n",
    "3. **Clustering**  \n",
    "   Messages were grouped using **MiniBatch K-Means** (`k = 300`).  \n",
    "   ~85% of clusters contained at least one labeled anchor.\n",
    "\n",
    "4. **Label propagation**  \n",
    "   For each anchored cluster, labels were propagated using **majority vote** from human-labeled messages.\n",
    "\n",
    "5. **Noise reduction**  \n",
    "   To reduce incorrect propagation, only the **closest 50% of samples per cluster** (by distance to centroid) were kept.\n",
    "\n",
    "6. **Dataset expansion**  \n",
    "   This produced **619 high-confidence pseudo-labeled messages**, expanding the training set by ~60% with no extra manual effort.\n",
    "\n",
    "---\n",
    "\n",
    "### Model Training\n",
    "A **Logistic Regression** classifier with:\n",
    "- TF-IDF text features\n",
    "- Numeric features (`len_words`, `is_question`)\n",
    "- Class-weight balancing\n",
    "\n",
    "was retrained on the **merged dataset** (manual + pseudo labels).\n",
    "\n",
    "---\n",
    "\n",
    "### Results\n",
    "Compared to the supervised-only baseline:\n",
    "\n",
    "- **Recall (important messages)** improved from ~0.40 → **0.63**\n",
    "- With threshold tuning (`p ≥ 0.3`), recall reached **~0.78**\n",
    "- Improvement achieved **without new human labels**\n",
    "\n",
    "This confirms that cluster-based semi-supervised learning effectively reduces missed important messages in a real-world, imbalanced setting.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaway\n",
    "Using human labeled messages as anchors and propagating labels within semantic clusters is an efficient and explainable way to scale personal text classification systems when labeled data is scarce."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
